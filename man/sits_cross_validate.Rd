% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/sits_assessment.R
\name{sits_cross_validate}
\alias{sits_cross_validate}
\title{Cross-validate temporal patterns}
\usage{
sits_cross_validate(data.tb, method = "gam", bands = NULL, times = 100,
  perc = 0.1, from = NULL, to = NULL, freq = 8, formula = y ~ s(x),
  tw_alpha = -0.1, tw_beta = 100, tw_theta = 0.5, tw_span = 0,
  interval = "12 month", overlap = 0.5, n_clusters = 2,
  grouping_method = "ward.D2", unsupervised = FALSE, min_clu_perc = 0.1,
  apply_gam = FALSE, koh_xgrid = 5, koh_ygrid = 5, koh_rlen = 100,
  koh_alpha = c(0.05, 0.01), file = "./conf_matrix.json", .multicores = 1,
  ...)
}
\arguments{
\item{data.tb}{a SITS tibble}

\item{method}{method to create patterns ("gam", "dendogram" or "centroids")}

\item{bands}{the bands used for classification}

\item{times}{number of partitions to create.}

\item{perc}{the percentage of data that goes to training.}

\item{from}{starting date of the estimate in month-day (for "gam" method)}

\item{to}{end data of the estimated in month-day (for "gam" method)}

\item{freq}{int - the interval in days for the estimates to be generated}

\item{formula}{the formula to be applied in the estimate (for "gam" method)}

\item{tw_alpha}{(double) - the steepness of the logistic function used for temporal weighting}

\item{tw_beta}{(integer) - the midpoint (in days) of the logistic function}

\item{tw_theta}{numeric between 0 and 1. The weight of the time for the TWDTW computation. Use theta=0 to cancel the time-weight, i.e. to run the original DTW algorithm. Default is 0.5. For details see dtwSat::twdtwApply help.}

\item{tw_span}{A number. Span between two matches, i.e. the minimum interval between two matches, for details see dtwSat::twdtwApply help.}

\item{interval}{A character with the intevals size, e.g. "6 month".}

\item{overlap}{A number between 0 and 1. The minimum overlapping between one match and the interval of classification. Default is 0.5. For details see dtwSat::twdtwApply help.}

\item{n_clusters}{the maximum number of clusters to be identified (for clustering methods)}

\item{grouping_method}{the agglomeration method to be used. Any `hclust` method (see `hclust`) (ignored in `kohonen` method). Default is 'ward.D2'.}

\item{unsupervised}{if TRUE, proceeds an unsupervised cluster followed by a relabel taking original label majority (
this option has not any effect if method == "gam")}

\item{min_clu_perc}{the minimum percentagem of valid cluster members, with reference to the total number of samples (for clustering methods)}

\item{apply_gam}{apply gam method after a clustering algorithm (ignored if method is `gam`).}

\item{koh_xgrid}{x dimension of the SOM grid (used only in `kohonen` or `kohonen-dendogram` methods). Defaul is 5.}

\item{koh_ygrid}{y dimension of the SOM grid (used only in `kohonen` or `kohonen-dendogram` methods). Defaul is 5.}

\item{koh_rlen}{the number of times the complete data set will be presented to the SOM grid.
(used only in `kohonen` or `kohonen-dendogram` methods). Default is 100.}

\item{koh_alpha}{learning rate, a vector of two numbers indicating the amount of change.
Default is to decline linearly from 0.05 to 0.01 over rlen updates.}

\item{file}{file to save the results}

\item{.multicores}{number of threads to process the validation (Linux only). Each process will run a whole partition validation (see `times` parameter).}

\item{...}{any additional parameters to be passed to `sits_pattern` function.}
}
\value{
cm             a validation assessment
}
\description{
Splits the set of time series into training and validation and
perform cross-validation.
Cross-validation is a model validation technique for assessing how the results
of a statistical analysis will generalize to an independent data set.
It is mainly used in settings where the goal is prediction,
and one wants to estimate how accurately a predictive model will perform in practice.
One round of cross-validation involves partitioning a sample of data
into complementary subsets, performing the analysis on one subset
(called the training set), and validating the analysis on the other subset
(called the validation set or testing set).
To reduce variability, multiple rounds of cross-validation
are performed using different partitions,
and the validation results are averaged over the rounds.

This function returns the Overall Accuracy, User's Accuracy,
Producer's Accuracy, error matrix (confusion matrix), and Kappa values.
}
\author{
Rolf Simoes, \email{rolf.simoes@inpe.br}

Victor Maus, \email{vwmaus1@gmail.com}

Gilberto Camara, \email{gilberto.camara@inpe.br}
}
